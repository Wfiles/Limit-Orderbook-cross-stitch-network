{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "\n",
    "from ignite.engine import Engine, Events, create_supervised_trainer, create_supervised_evaluator\n",
    "from ignite.metrics import Accuracy, Loss\n",
    "from ignite.metrics.regression import MeanAbsoluteRelativeError\n",
    "from ignite.handlers import ModelCheckpoint\n",
    "from ignite.contrib.handlers import TensorboardLogger, global_step_from_engine\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from Cross_Stitch_models.cross_stitch_network import CrossStitchNetwork\n",
    "from utils.dynamic_losses import MultiTaskDynamicLoss\n",
    "from ignite.metrics import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "TRAINING_PATH = 'data'\n",
    "TESTING_PATH = 'data'\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")  # Use CUDA if available\n",
    "elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")  # Use MPS for Apple Silicon if available\n",
    "else:\n",
    "    device = torch.device(\"cpu\")  # Fallback to CPU\n",
    "\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(149, 254750) (149, 139587)\n"
     ]
    }
   ],
   "source": [
    "dec_train = np.loadtxt(f'{TRAINING_PATH}/Train_Dst_NoAuction_DecPre_CF_7.txt')\n",
    "\n",
    "\n",
    "dec_test1 = np.loadtxt(f'{TESTING_PATH}/Test_Dst_NoAuction_DecPre_CF_7.txt')\n",
    "dec_test2 = np.loadtxt(f'{TESTING_PATH}/Test_Dst_NoAuction_DecPre_CF_8.txt')\n",
    "dec_test3 = np.loadtxt(f'{TESTING_PATH}/Test_Dst_NoAuction_DecPre_CF_9.txt')\n",
    "dec_test = np.hstack((dec_test1, dec_test2, dec_test3))\n",
    "\n",
    "print(dec_train.shape, dec_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __extract_stock__(df, stock_idx, test = False, val = False):\n",
    "    \"\"\"\n",
    "    Extract specific stock data from a DataFrame using stock index.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df: Pandas DataFrame\n",
    "        Input DataFrame containing raw stock data.\n",
    "    stock_idx: {0, 1, 2, 3, 4}\n",
    "        Index of the stock to extract.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Pandas DataFrame\n",
    "        Extracted stock data.\n",
    "    \"\"\"\n",
    "    if test :\n",
    "        n_boundaries = 14\n",
    "    else :\n",
    "        n_boundaries = 4\n",
    "\n",
    "    # Calculate boundaries based on changes in the midprice column\n",
    "    boundaries = np.sort(\n",
    "        np.argsort(np.abs(np.diff(df['midprice'], prepend=np.inf)))[-n_boundaries - 1:]\n",
    "    )\n",
    "\n",
    "    # Append the last index as the upper boundary\n",
    "    boundaries = np.append(boundaries, [len(df)])\n",
    "\n",
    "    # Split the data into segments based on the calculated boundaries\n",
    "    split_data = [df.iloc[boundaries[i] : boundaries[i + 1]] for i in range(n_boundaries + 1)]\n",
    "\n",
    "    # Return the segment corresponding to the stock_idx\n",
    "    return split_data[stock_idx]\n",
    "\n",
    "def extract_all_stocks(df, test = False):\n",
    "    \"\"\"\n",
    "    Extract all stocks from a DataFrame and assign stock identifiers.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df: Pandas DataFrame\n",
    "        Input DataFrame containing raw stock data.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Pandas DataFrame\n",
    "        A combined DataFrame of all extracted stocks with a 'STOCK' column.\n",
    "    \"\"\"\n",
    "    stocks = []\n",
    "    if test : \n",
    "        #Since test is made of 3 days, there are three days of data, so 5 stocks per day\n",
    "        length = 15\n",
    "    else : \n",
    "        length = 5\n",
    "    for stock_idx in range(length):\n",
    "        stock_data = __extract_stock__(df, stock_idx, test)\n",
    "        \n",
    "        # Assign stock identifier wheter it is testing or training\n",
    "        if test : \n",
    "            stock_data['STOCK'] = stock_idx%5\n",
    "            stock_data['DAY'] = 7 + stock_idx//5\n",
    "        else : \n",
    "            stock_data['STOCK'] = stock_idx\n",
    "        stocks.append(stock_data)\n",
    "    return pd.concat(stocks, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_dataframe(array) -> pd.DataFrame:\n",
    "    data = {}\n",
    "\n",
    "    for level in range(10):\n",
    "        data[f\"PRICE_ASK_{level}\"] = array[4 * level]\n",
    "    for level in range(10):\n",
    "        data[f\"PRICE_BID_{level}\"] = array[4 * level + 2]\n",
    "    for level in range(10):\n",
    "        data[f\"VOLUME_ASK_{level}\"] = array[4 * level + 1]\n",
    "    for level in range(10):\n",
    "        data[f\"VOLUME_BID_{level}\"] = array[4 * level + 3]\n",
    "    data['midprice'] = data['PRICE_ASK_0'] + data['PRICE_BID_0']\n",
    "\n",
    "    return pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = to_dataframe(dec_train)\n",
    "df_test = to_dataframe(dec_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = extract_all_stocks(df_train)\n",
    "df_test =extract_all_stocks(df_test, test=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "stocks = df_train.groupby('STOCK')\n",
    "\n",
    "# Create a plot for each stock\n",
    "plt.figure(figsize=(10, 6))\n",
    "for stock, group in stocks:\n",
    "    plt.plot(group['midprice'], label=f\"Stock: {stock}\")\n",
    "\n",
    "plt.title(\"Stock Values Over Time day training\")\n",
    "plt.xlabel(\"Index\")\n",
    "plt.ylabel(\"Value\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Stock: 0\n",
      "Stock 0 - Train Size: 23137, Test Size: 6209\n",
      "Processing Stock: 1\n",
      "Stock 1 - Train Size: 44675, Test Size: 22862\n",
      "Processing Stock: 2\n",
      "Stock 2 - Train Size: 38350, Test Size: 24150\n",
      "Processing Stock: 3\n",
      "Stock 3 - Train Size: 54476, Test Size: 31731\n",
      "Processing Stock: 4\n",
      "Stock 4 - Train Size: 93117, Test Size: 53640\n",
      "Data preparation complete for all stocks.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "\n",
    "def horizon_volatility_log_return(mid_prices, horizon):\n",
    "    \"\"\"\n",
    "    Calculate rolling volatility based on log returns over a given horizon.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    mid_prices : numpy.ndarray\n",
    "        Array of mid-prices.\n",
    "    horizon : int\n",
    "        Horizon over which to calculate log return volatility.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    numpy.ndarray\n",
    "        Rolling volatility based on log returns.\n",
    "    \"\"\"\n",
    "    log_returns = np.log(mid_prices[1:] / mid_prices[:-1])\n",
    "    volatility = np.sqrt(np.convolve(log_returns ** 2, np.ones(horizon), mode='valid') / horizon)\n",
    "\n",
    "\n",
    "    scale_volatility = (volatility)*1000\n",
    "\n",
    "    return scale_volatility\n",
    "\n",
    "def data_time_length(X, Y, T):\n",
    "    \"\"\"\n",
    "    Prepare time-series data for a given time length.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    X : numpy.ndarray\n",
    "        Input features.\n",
    "    Y : numpy.ndarray\n",
    "        Target variables.\n",
    "    T : int\n",
    "        Time length for sequences.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    tuple\n",
    "        Tuple containing:\n",
    "        - dataX: Prepared input features (time-series format).\n",
    "        - dataY: Corresponding target variables.\n",
    "    \"\"\"\n",
    "    N, D = X.shape\n",
    "    dataY = np.array(Y[T - 1:N])\n",
    "    dataX = np.zeros((N - T + 1, T, D))\n",
    "    for i in range(T, N + 1):\n",
    "        dataX[i - T] = X[i - T:i, :]\n",
    "    return dataX, dataY\n",
    "\n",
    "# Custom PyTorch Dataset class\n",
    "class VolatilityDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Custom Dataset class for volatility forecasting.\n",
    "    \"\"\"\n",
    "    def __init__(self, data, horizons, T, mean=None, std=None, compute_stats=False):\n",
    "        \"\"\"\n",
    "        Initialization of the dataset.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        data : pandas.DataFrame\n",
    "            Input DataFrame with features and target variables.\n",
    "        horizons : list\n",
    "            List of horizons for which to compute features.\n",
    "        T : int\n",
    "            Time length for sequences.\n",
    "        mean : np.ndarray\n",
    "            Precomputed mean values for normalization.\n",
    "        std : np.ndarray\n",
    "            Precomputed standard deviation values for normalization.\n",
    "        compute_stats : bool\n",
    "            Whether to compute mean and std from the dataset.\n",
    "        \"\"\"\n",
    "        self.horizons = horizons\n",
    "        self.T = T\n",
    "\n",
    "        # Extract features (excluding mid_price and STOCK)\n",
    "        self.features = data.loc[:, data.columns.str.contains('PRICE|VOLUME')].values\n",
    "\n",
    "        # Extract mid-prices for calculating volatility\n",
    "        mid_prices = data['midprice'].values\n",
    "\n",
    "        # Compute rolling volatility\n",
    "        rolling_volatility = []\n",
    "        min_length = len(mid_prices) - max(horizons)  # Use the smallest valid length\n",
    "        for horizon in horizons:\n",
    "            rv = horizon_volatility_log_return(mid_prices, horizon)\n",
    "            rolling_volatility.append(rv[:min_length])  # Truncate to minimum valid length\n",
    "\n",
    "        rolling_volatility = np.array(rolling_volatility).T  # Shape: [min_length, len(horizons)]\n",
    "\n",
    "        # Align features with valid rolling volatility length\n",
    "        self.features = self.features[:min_length]\n",
    "        valid_indices = ~np.isnan(rolling_volatility).any(axis=1)\n",
    "\n",
    "        # Apply valid indices\n",
    "        self.features = self.features[valid_indices]\n",
    "        rolling_volatility = rolling_volatility[valid_indices, :]\n",
    "\n",
    "        self.y = rolling_volatility\n",
    "\n",
    "        # Normalize features\n",
    "        if compute_stats:\n",
    "            self.mean = self.features.mean(axis=0)\n",
    "            self.std = self.features.std(axis=0)\n",
    "        else:\n",
    "            self.mean = mean\n",
    "            self.std = std\n",
    "\n",
    "        # Apply normalization\n",
    "        self.features = (self.features - self.mean) / (self.std + 1e-8)\n",
    "\n",
    "        # Convert to time-series format\n",
    "        self.features, self.y = data_time_length(self.features, self.y, self.T)\n",
    "        self.features = self.features[:, None, :, :]  # Add channel dimension for PyTorch\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Returns the total number of samples.\"\"\"\n",
    "        return self.features.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"Generates one sample of data.\"\"\"\n",
    "        return torch.tensor(self.features[index], dtype=torch.float32), torch.tensor(self.y[index], dtype=torch.float32)\n",
    "\n",
    "# Parameters\n",
    "batch_size = 32\n",
    "horizons = [20, 50, 100]\n",
    "T = 100\n",
    "\n",
    "unique_stocks = df_train['STOCK'].unique()\n",
    "\n",
    "# Dictionary to store DataLoaders for each stock\n",
    "dataloaders = {}\n",
    "\n",
    "for stock in unique_stocks:\n",
    "    print(f\"Processing Stock: {stock}\")\n",
    "\n",
    "    # Filter data for the current stock\n",
    "    stock_data_train = df_train[df_train['STOCK'] == stock]\n",
    "    stock_data_test = df_test[df_test['STOCK'] == stock]\n",
    "\n",
    "    # Compute mean and std from the training set\n",
    "    train_dataset = VolatilityDataset(stock_data_train, horizons=horizons, T=T, compute_stats=True)\n",
    "    train_mean, train_std = train_dataset.mean, train_dataset.std\n",
    "    # Use the same normalization statistics for the test set\n",
    "    test_dataset = VolatilityDataset(stock_data_test, horizons=horizons, T=T, mean=train_mean, std=train_std)\n",
    "\n",
    "    # Create DataLoaders\n",
    "    train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=False, pin_memory=True)\n",
    "    test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False, pin_memory=True)\n",
    "\n",
    "    # Store DataLoaders in the dictionary\n",
    "    dataloaders[stock] = {\n",
    "        'train_loader': train_loader,\n",
    "        'test_loader': test_loader\n",
    "    }\n",
    "\n",
    "    print(f\"Stock {stock} - Train Size: {len(train_dataset)}, Test Size: {len(test_dataset)}\")\n",
    "\n",
    "print(\"Data preparation complete for all stocks.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-19 11:04:44.487310: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from ignite.engine import Engine, Events\n",
    "from ignite.handlers import Checkpoint, DiskSaver, global_step_from_engine, EarlyStopping\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import gc\n",
    "from ignite.contrib.handlers import ProgressBar\n",
    "import time\n",
    "\n",
    "def create_supervised_trainer(index_testing) :\n",
    "  # Clear unused GPU memory\n",
    "  torch.cuda.empty_cache()  \n",
    "  gc.collect()  \n",
    "\n",
    "  # Initialize TensorBoard writer\n",
    "  writer = SummaryWriter(log_dir=\"../t3-dl-lob/data/runs/cross_stitch_network\")\n",
    "\n",
    "  #initialize experimentation settings\n",
    "  torch.set_default_dtype(torch.float32)\n",
    "  torch.cuda.manual_seed(42)\n",
    "  torch.backends.cudnn.deterministic = True\n",
    "  torch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n",
    "  # Initialize model and move to the correct device\n",
    "  number_of_tasks = len(horizons)\n",
    "  time_span = torch.linspace(0, 1, 100, dtype=torch.float32).to(device)\n",
    "  model = CrossStitchNetwork(number_of_tasks=number_of_tasks, time_span=time_span)\n",
    "  model.to(device)\n",
    "\n",
    "  # Loss function and optimizer\n",
    "  is_regression = torch.Tensor([True, True, True]).to(device)\n",
    "  criterion = MultiTaskDynamicLoss(is_regression=is_regression, reduction='mean')\n",
    "  optimizer = torch.optim.Adam(model.parameters(), lr=1e-2, weight_decay=1e-5)\n",
    "\n",
    "  # Training function\n",
    "  def update_function(engine, batch):\n",
    "    start_time = time.time()\n",
    "    input1, targets = batch\n",
    "\n",
    "    # Move data to GPU with non_blocking transfers\n",
    "    input1 = input1.to(device, non_blocking=True)\n",
    "    targets = targets.to(device, non_blocking=True)\n",
    "\n",
    "    # Clone inputs for multi-task processing\n",
    "    inputs = [input1.clone() for _ in range(number_of_tasks)]\n",
    "\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "\n",
    "    predictions = model(*inputs)\n",
    "    # Compute individual task losses\n",
    "    losses = [torch.mean(torch.abs(pred- targets[:, i])) for i, pred in enumerate(predictions)]\n",
    "\n",
    "    # Aggregate losses\n",
    "    loss = criterion(torch.stack(losses))\n",
    "\n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    end_time = time.time()\n",
    "\n",
    "    return loss.item()\n",
    "\n",
    "  # Inference function\n",
    "  def inference(engine, batch):\n",
    "    input1, targets = batch\n",
    "\n",
    "    # Move data to GPU with non_blocking transfers (if pinned memory is supported)\n",
    "    input1 = input1.to(device, non_blocking=True)\n",
    "    targets = targets.to(device, non_blocking=True)\n",
    "\n",
    "    # Clone inputs for multi-task processing\n",
    "    inputs = [input1.clone() for _ in range(number_of_tasks)]\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        predictions = model(*inputs)\n",
    "\n",
    "    return {f'out{i+1}': (pred, targets[:, i]) for i, pred in enumerate(predictions)}\n",
    "\n",
    "  # Create training and validation engines\n",
    "  trainer = Engine(update_function)\n",
    "  validator = Engine(inference)\n",
    "\n",
    "  # Create time-stamp for the current run\n",
    "  pbar = ProgressBar()\n",
    "  pbar.attach(trainer)\n",
    "  pbar = ProgressBar()\n",
    "  pbar.attach(validator)\n",
    "\n",
    "  # Define the checkpoint handler\n",
    "  checkpointer = Checkpoint(\n",
    "    to_save={'model': model, 'optimizer': optimizer},  \n",
    "    save_handler=DiskSaver(dirname='\"/content/gdrive/MyDrive/t3-dl-lob/data/checkpoints', create_dir=True, require_empty=False),  \n",
    "    n_saved=2  # Keep the last 2 checkpoints\n",
    "  )\n",
    "\n",
    "  # Attach the checkpoint handler to the trainer\n",
    "  trainer.add_event_handler(Events.EPOCH_COMPLETED(every=1), checkpointer)\n",
    "\n",
    "  # Attach metrics to the validator\n",
    "  def output_transform_horizon(index):\n",
    "    def transform(output):\n",
    "        y_pred, y_true = output[f'out{index + 1}']\n",
    "        scale = 1000\n",
    "        y_pred_scaled_back = (y_pred)/scale\n",
    "        y_true_scaled_back = (y_true)/scale\n",
    "        mask = y_true_scaled_back != 0\n",
    "        if y_pred_scaled_back.dim() > 1 and y_pred_scaled_back.shape[1] == 1:  # Check if squeezing is needed\n",
    "            y_pred_scaled_back = y_pred_scaled_back.squeeze(1)\n",
    "        return y_pred_scaled_back[mask], y_true_scaled_back[mask]\n",
    "    return transform\n",
    "\n",
    "  # Attach metrics to the validator\n",
    "  for i, horizon in enumerate(horizons):\n",
    "    MeanAbsoluteRelativeError(output_transform=output_transform_horizon(i)).attach(\n",
    "        validator, f'Mean Absolute Relative Error Horizon {horizon}'\n",
    "    )\n",
    "\n",
    "  # Attach the loss metric\n",
    "  @trainer.on(Events.EPOCH_COMPLETED)\n",
    "  def validate(engine):\n",
    "    validator.run(dataloaders[index_testing]['test_loader'])\n",
    "    metrics = validator.state.metrics\n",
    "    for metric_name, value in metrics.items():\n",
    "        writer.add_scalar(metric_name, value, engine.state.epoch)\n",
    "        print(f\"{metric_name}: {value:.4f}\")\n",
    "\n",
    "  # Log training loss to TensorBoard\n",
    "  @trainer.on(Events.ITERATION_COMPLETED(every=1))\n",
    "  def log_training(engine):\n",
    "    iteration = engine.state.iteration\n",
    "    loss = engine.state.output\n",
    "    if iteration % 10 == 0:\n",
    "        writer.add_scalar(\"Loss/train\", loss, iteration)  \n",
    "\n",
    "  # Close TensorBoard writer\n",
    "  @trainer.on(Events.COMPLETED)\n",
    "  def close_writer(engine):\n",
    "    writer.close()\n",
    "    print(\"TensorBoard writer closed.\")\n",
    "\n",
    "  return trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for stock 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Engine run is terminating due to exception: \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining for stock \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m trainer \u001b[38;5;241m=\u001b[39m create_supervised_trainer(i)\n\u001b[0;32m----> 5\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataloaders\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain_loader\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining completed for stock \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Check TensorBoard for metrics and profiling.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/ML-project2/lib/python3.11/site-packages/ignite/engine/engine.py:889\u001b[0m, in \u001b[0;36mEngine.run\u001b[0;34m(self, data, max_epochs, epoch_length)\u001b[0m\n\u001b[1;32m    886\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mdataloader \u001b[38;5;241m=\u001b[39m data\n\u001b[1;32m    888\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minterrupt_resume_enabled:\n\u001b[0;32m--> 889\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_internal_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    891\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_run_legacy()\n",
      "File \u001b[0;32m~/anaconda3/envs/ML-project2/lib/python3.11/site-packages/ignite/engine/engine.py:932\u001b[0m, in \u001b[0;36mEngine._internal_run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    930\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_run_generator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_run_as_gen()\n\u001b[1;32m    931\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 932\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_internal_run_generator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    933\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m out:\n\u001b[1;32m    934\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_run_generator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/ML-project2/lib/python3.11/site-packages/ignite/engine/engine.py:990\u001b[0m, in \u001b[0;36mEngine._internal_run_as_gen\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    988\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataloader_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    989\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEngine run is terminating due to exception: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 990\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle_exception\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    992\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataloader_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    993\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\n",
      "File \u001b[0;32m~/anaconda3/envs/ML-project2/lib/python3.11/site-packages/ignite/engine/engine.py:644\u001b[0m, in \u001b[0;36mEngine._handle_exception\u001b[0;34m(self, e)\u001b[0m\n\u001b[1;32m    642\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fire_event(Events\u001b[38;5;241m.\u001b[39mEXCEPTION_RAISED, e)\n\u001b[1;32m    643\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 644\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[0;32m~/anaconda3/envs/ML-project2/lib/python3.11/site-packages/ignite/engine/engine.py:956\u001b[0m, in \u001b[0;36mEngine._internal_run_as_gen\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    953\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataloader_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    954\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setup_engine()\n\u001b[0;32m--> 956\u001b[0m epoch_time_taken \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_once_on_dataset_as_gen()\n\u001b[1;32m    958\u001b[0m \u001b[38;5;66;03m# time is available for handlers but must be updated after fire\u001b[39;00m\n\u001b[1;32m    959\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mtimes[Events\u001b[38;5;241m.\u001b[39mEPOCH_COMPLETED\u001b[38;5;241m.\u001b[39mname] \u001b[38;5;241m=\u001b[39m epoch_time_taken\n",
      "File \u001b[0;32m~/anaconda3/envs/ML-project2/lib/python3.11/site-packages/ignite/engine/engine.py:1077\u001b[0m, in \u001b[0;36mEngine._run_once_on_dataset_as_gen\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1074\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fire_event(Events\u001b[38;5;241m.\u001b[39mITERATION_STARTED)\n\u001b[1;32m   1075\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_terminate_or_interrupt()\n\u001b[0;32m-> 1077\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39moutput \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1078\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fire_event(Events\u001b[38;5;241m.\u001b[39mITERATION_COMPLETED)\n\u001b[1;32m   1079\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_terminate_or_interrupt()\n",
      "Cell \u001b[0;32mIn[10], line 50\u001b[0m, in \u001b[0;36mcreate_supervised_trainer.<locals>.update_function\u001b[0;34m(engine, batch)\u001b[0m\n\u001b[1;32m     46\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m     47\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 50\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;66;03m# Compute individual task losses\u001b[39;00m\n\u001b[1;32m     52\u001b[0m losses \u001b[38;5;241m=\u001b[39m [torch\u001b[38;5;241m.\u001b[39mmean(torch\u001b[38;5;241m.\u001b[39mabs(pred\u001b[38;5;241m-\u001b[39m targets[:, i])) \u001b[38;5;28;01mfor\u001b[39;00m i, pred \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(predictions)]\n",
      "File \u001b[0;32m~/anaconda3/envs/ML-project2/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/ML-project2/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/EPFL/2024-25/MA1/CS-433 Machine learning/Project 2/nouveau-git/t3-dl-lob/Cross_Stitch_models/cross_stitch_network.py:42\u001b[0m, in \u001b[0;36mCrossStitchNetwork.forward\u001b[0;34m(self, *tasks)\u001b[0m\n\u001b[1;32m     39\u001b[0m outputs \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, task \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(conv_outputs):\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;66;03m# Reshape task input for ODE\u001b[39;00m\n\u001b[0;32m---> 42\u001b[0m     task_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mode\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;66;03m# Map ODE output to task-specific output\u001b[39;00m\n\u001b[1;32m     45\u001b[0m     task_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtask_fcs[i](task_out[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :])  \u001b[38;5;66;03m# Use final time step's output\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/ML-project2/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/ML-project2/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/EPFL/2024-25/MA1/CS-433 Machine learning/Project 2/nouveau-git/t3-dl-lob/Cross_Stitch_models/ode_layer.py:13\u001b[0m, in \u001b[0;36mODE.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;66;03m# Integrate the ODE using odeint\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43modeint\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mode_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtime_span\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrk4\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/ML-project2/lib/python3.11/site-packages/torchdiffeq/_impl/odeint.py:80\u001b[0m, in \u001b[0;36modeint\u001b[0;34m(func, y0, t, rtol, atol, method, options, event_fn)\u001b[0m\n\u001b[1;32m     77\u001b[0m solver \u001b[38;5;241m=\u001b[39m SOLVERS[method](func\u001b[38;5;241m=\u001b[39mfunc, y0\u001b[38;5;241m=\u001b[39my0, rtol\u001b[38;5;241m=\u001b[39mrtol, atol\u001b[38;5;241m=\u001b[39matol, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m event_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 80\u001b[0m     solution \u001b[38;5;241m=\u001b[39m \u001b[43msolver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mintegrate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     82\u001b[0m     event_t, solution \u001b[38;5;241m=\u001b[39m solver\u001b[38;5;241m.\u001b[39mintegrate_until_event(t[\u001b[38;5;241m0\u001b[39m], event_fn)\n",
      "File \u001b[0;32m~/anaconda3/envs/ML-project2/lib/python3.11/site-packages/torchdiffeq/_impl/solvers.py:117\u001b[0m, in \u001b[0;36mFixedGridODESolver.integrate\u001b[0;34m(self, t)\u001b[0m\n\u001b[1;32m    114\u001b[0m dy, f0 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_step_func(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc, t0, dt, t1, y0)\n\u001b[1;32m    115\u001b[0m y1 \u001b[38;5;241m=\u001b[39m y0 \u001b[38;5;241m+\u001b[39m dy\n\u001b[0;32m--> 117\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m j \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(t) \u001b[38;5;129;01mand\u001b[39;00m t1 \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m t[j]:\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minterp \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlinear\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    119\u001b[0m         solution[j] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_linear_interp(t0, t1, y0, y1, t[j])\n",
      "File \u001b[0;32m~/anaconda3/envs/ML-project2/lib/python3.11/site-packages/torch/_tensor.py:996\u001b[0m, in \u001b[0;36mTensor.__len__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    993\u001b[0m \u001b[38;5;21m__neg__\u001b[39m \u001b[38;5;241m=\u001b[39m _C\u001b[38;5;241m.\u001b[39mTensorBase\u001b[38;5;241m.\u001b[39mneg\n\u001b[1;32m    994\u001b[0m \u001b[38;5;21m__abs__\u001b[39m \u001b[38;5;241m=\u001b[39m _C\u001b[38;5;241m.\u001b[39mTensorBase\u001b[38;5;241m.\u001b[39mabs\n\u001b[0;32m--> 996\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__len__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    997\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    998\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(Tensor\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__len__\u001b[39m, (\u001b[38;5;28mself\u001b[39m,), \u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#For each stock, train the model\n",
    "for i in range(5) :\n",
    "  print(f'Training for stock {i + 1}')\n",
    "  trainer = create_supervised_trainer(i)\n",
    "  trainer.run(dataloaders[i]['train_loader'], max_epochs=5)\n",
    "  print(f\"Training completed for stock {i + 1}. Check TensorBoard for metrics and profiling.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training and testing of the TFT transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_dataframe(array) -> pd.DataFrame:\n",
    "    data = {}\n",
    "    for level in range(10):\n",
    "        data[f\"PRICE_ASK_{level}\"] = array[4 * level]\n",
    "    for level in range(10):\n",
    "        data[f\"PRICE_BID_{level}\"] = array[4 * level + 2]\n",
    "    for level in range(10):\n",
    "        data[f\"VOLUME_ASK_{level}\"] = array[4 * level + 1]\n",
    "    for level in range(10):\n",
    "        data[f\"VOLUME_BID_{level}\"] = array[4 * level + 3]\n",
    "    data['midprice'] = data['PRICE_ASK_0'] + data['PRICE_BID_0']\n",
    "    data['SPREAD'] = data['PRICE_ASK_0'] - data['PRICE_BID_0']\n",
    "\n",
    "    return pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = to_dataframe(dec_train)\n",
    "df_test = to_dataframe(dec_test)\n",
    "df_train = extract_all_stocks(df_train)\n",
    "df_test =extract_all_stocks(df_test, test=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_stock_group(group):\n",
    "    # Calculate log mid price\n",
    "    group['log_midprice'] = np.log(group['midprice'])\n",
    "    \n",
    "    # Calculate log return\n",
    "    group['log_return'] = group['log_midprice'].diff()\n",
    "    \n",
    "    # Calculate rolling volatility for different windows\n",
    "    for k in [20, 50, 100]:\n",
    "        group[f'rolling_volatility_{k}'] = group['log_return'].rolling(window=k).std()\n",
    "    \n",
    "    return group\n",
    "\n",
    "# Apply the function to each group\n",
    "train_dataframe = df_train.groupby('STOCK').apply(process_stock_group)\n",
    "test_dataframe = df_test.groupby('STOCK').apply(process_stock_group)\n",
    "\n",
    "train_dataframe.reset_index(drop=True, inplace=True)\n",
    "test_dataframe.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataframe['DAY'] = -1\n",
    "\n",
    "train_dataframe.dropna(inplace=True, subset=['log_return', 'rolling_volatility_20', 'rolling_volatility_50', 'rolling_volatility_100'])\n",
    "test_dataframe.dropna(inplace=True, subset=['log_return', 'rolling_volatility_20', 'rolling_volatility_50', 'rolling_volatility_100'])\n",
    "\n",
    "df = pd.concat([train_dataframe, test_dataframe])\n",
    "df['id'] = 0\n",
    "df['time'] = df.groupby('DAY').cumcount()\n",
    "df['dummy_col'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Temporal_Fusion_Transform.data_formatters.volatility import VolatilityFormatter\n",
    "from Temporal_Fusion_Transform.data_formatters import ts_dataset  \n",
    "from Temporal_Fusion_Transform import tft_model\n",
    "\n",
    "\n",
    "#Define the transformer\n",
    "def initialize_Transformer(horizon) : \n",
    "    data_formatter = VolatilityFormatter()\n",
    "    df.rename(columns={f'rolling_volatility_{horizon}': 'rolling_volatility'}, inplace=True)\n",
    "    train, valid, test = data_formatter.split_data(df)\n",
    "    train_samples, valid_samples = data_formatter.get_num_samples_for_calibration(\n",
    "    )\n",
    "\n",
    "    # Sets up default params\n",
    "    fixed_params = data_formatter.get_experiment_params(horizon)\n",
    "    params = data_formatter.get_default_model_params()\n",
    "    #Set the parameters for the fusiontime transformer\n",
    "    id_col = 'id'\n",
    "    time_col='time'\n",
    "\n",
    "    input_cols = ['STOCK', 'dummy_col', 'PRICE_ASK_0','PRICE_BID_0','VOLUME_ASK_0', 'VOLUME_BID_0','SPREAD','midprice']\n",
    "\n",
    "    static_col = 'STOCK'\n",
    "    target_col = 'rolling_volatility'\n",
    "    time_steps=192\n",
    "    num_encoder_steps = 168\n",
    "    output_size = 1\n",
    "    max_samples = 258000\n",
    "    num_statics = 1\n",
    "    input_size = 8\n",
    "\n",
    "    vol = ts_dataset.TSDataset(id_col, static_col,time_col, input_cols,target_col, time_steps, max_samples,input_size, num_encoder_steps, num_statics,output_size, train)\n",
    "\n",
    "    batch_size=64\n",
    "    loader = DataLoader(\n",
    "                vol,\n",
    "                batch_size=batch_size,\n",
    "                num_workers=2,\n",
    "                shuffle=True\n",
    "            )\n",
    "    for batch in loader :\n",
    "        break\n",
    "    static_cols = ['STOCK']\n",
    "    categorical_cols = ['dummy_col']\n",
    "    real_cols = ['PRICE_ASK_0','PRICE_BID_0','VOLUME_ASK_0', 'VOLUME_BID_0','SPREAD','midprice']\n",
    "\n",
    "    config = {}\n",
    "    config['static_variables'] = 1\n",
    "    config['time_varying_categoical_variables'] = 1\n",
    "    config['time_varying_real_variables_encoder'] = 4\n",
    "    config['time_varying_real_variables_decoder'] = 3\n",
    "    config['num_masked_series'] = 1\n",
    "    config['seq_length'] = vol.time_steps\n",
    "    config['static_embedding_vocab_sizes'] = [369]\n",
    "    config['time_varying_embedding_vocab_sizes'] = [369]\n",
    "    config['embedding_dim'] = 8\n",
    "    config['lstm_hidden_dimension'] = 160\n",
    "    config['lstm_layers'] = 15\n",
    "    config['dropout'] = 0.05\n",
    "    config['device'] = 'cpu'\n",
    "    config['batch_size'] = 64\n",
    "    config['encode_length'] = 168\n",
    "    config['attn_heads'] = 4\n",
    "    config['num_quantiles'] = 3\n",
    "    config['vailid_quantiles'] = [0.1,0.5,0.9]\n",
    "    model = tft_model.TFT(config)\n",
    "    output,encoder_output, decoder_output, \\\n",
    "    attn,attn_output_weights, \\\n",
    "    static_embedding, embeddings_encoder = model.forward(batch)\n",
    "    df.rename(columns={'rolling_volatility': f'rolling_volatility_{horizon}'}, inplace=True)\n",
    "    return model, loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "\n",
    "#Run the fusiontime transformer\n",
    "def run_model(model, loader) : \n",
    "    q_loss_func = tft_model.QuantileLoss([0.1, 0.5, 0.9])\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    model.train()\n",
    "    epochs=10\n",
    "    losses = []\n",
    "    for i in range(epochs):\n",
    "        epoch_loss = [] \n",
    "        j=0\n",
    "        for batch in loader:\n",
    "            output = model(batch)\n",
    "            \n",
    "            inputs = batch['inputs']\n",
    "            outputs = batch['outputs']\n",
    "            predictions, *other_outputs = output\n",
    "\n",
    "            loss = q_loss_func(predictions[:,:,:].view(-1,3), outputs[:,:,0].flatten().float())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss.append(loss.item())\n",
    "            j+=1\n",
    "            if j>5:\n",
    "                break\n",
    "        losses.append(np.mean(epoch_loss))\n",
    "        print(np.mean(epoch_loss))\n",
    "    # Randomly choose an index\n",
    "    ind = np.random.choice(64)\n",
    "    print(f\"Selected index: {ind}\")\n",
    "\n",
    "    # Extract predictions and true values\n",
    "    pred_1 = predictions[ind, :, 0].detach().cpu().numpy()\n",
    "    pred_5 = predictions[ind, :, 1].detach().cpu().numpy()\n",
    "    pred_9 = predictions[ind, :, 2].detach().cpu().numpy()\n",
    "    true_values = batch['outputs'][ind, :, 0].detach().cpu().numpy()\n",
    "\n",
    "    # Calculate MARE\n",
    "    def mean_absolute_relative_error(pred, true):\n",
    "        mask = true != 0  # Avoid division by zero\n",
    "        return np.mean(np.abs((pred[mask] - true[mask]) / true[mask]))\n",
    "\n",
    "    mare_1 = mean_absolute_relative_error(pred_1, true_values)\n",
    "    mare_5 = mean_absolute_relative_error(pred_5, true_values)\n",
    "    mare_9 = mean_absolute_relative_error(pred_9, true_values)\n",
    "\n",
    "    print(f\"MARE (Quantile 1): {mare_1:.4f}\")\n",
    "    print(f\"MARE (Quantile 5): {mare_5:.4f}\")\n",
    "    print(f\"MARE (Quantile 9): {mare_9:.4f}\")\n",
    "\n",
    "    # Plot predictions and true values\n",
    "    plt.plot(pred_1, label=f'pred_1 (MARE={mare_1:.4f})')\n",
    "    plt.plot(pred_5, label=f'pred_5 (MARE={mare_5:.4f})')\n",
    "    plt.plot(pred_9, label=f'pred_9 (MARE={mare_9:.4f})')\n",
    "    plt.plot(true_values, label='true', linestyle='--')\n",
    "\n",
    "    plt.legend()\n",
    "    plt.title(\"Predictions vs True Values\")\n",
    "    plt.xlabel(\"Time Step\")\n",
    "    plt.ylabel(\"Value\")\n",
    "    plt.show()\n",
    "    mae_50_all = []\n",
    "\n",
    "    # Updated mean_absolute_relative_error function\n",
    "    def mean_absolute_relative_error(pred, true):\n",
    "        mask = true != 0  # Avoid division by zero\n",
    "        if not mask.any():  # Handle cases where true is all zeros\n",
    "            return np.nan\n",
    "        return np.mean(np.abs((pred[mask] - true[mask]) / true[mask]))\n",
    "\n",
    "    # Loop through all samples\n",
    "    for i in range(predictions.shape[0]):\n",
    "        pred_5_all = predictions[i, :, 1].detach().cpu().numpy()\n",
    "        true_values_all = batch['outputs'][i, :, 0].detach().cpu().numpy()\n",
    "        mae_50_all.append(mean_absolute_relative_error(pred_5_all, true_values_all))\n",
    "\n",
    "    # Calculate the mean MAE while ignoring NaN values\n",
    "    mean_mae_50 = np.nanmean(mae_50_all)\n",
    "    print(f\"Mean MAE for the 50th quantile over all samples: {mean_mae_50:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formatting train-valid-test splits.\n",
      "Setting scalers with training data...\n",
      "Getting valid sampling locations.\n",
      "Max samples=258000 exceeds # available segments=254059\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#Run the model for different horizons\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m horizon \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m20\u001b[39m, \u001b[38;5;241m50\u001b[39m, \u001b[38;5;241m100\u001b[39m] :\n\u001b[0;32m----> 3\u001b[0m     model, loader \u001b[38;5;241m=\u001b[39m \u001b[43minitialize_Transformer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhorizon\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining for horizon \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhorizon\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m     run_model(model, loader)\n",
      "Cell \u001b[0;32mIn[16], line 32\u001b[0m, in \u001b[0;36minitialize_Transformer\u001b[0;34m(horizon)\u001b[0m\n\u001b[1;32m     29\u001b[0m num_statics \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     30\u001b[0m input_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m8\u001b[39m\n\u001b[0;32m---> 32\u001b[0m vol \u001b[38;5;241m=\u001b[39m \u001b[43mts_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTSDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mid_col\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstatic_col\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtime_col\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_cols\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtarget_col\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime_steps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43minput_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_encoder_steps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_statics\u001b[49m\u001b[43m,\u001b[49m\u001b[43moutput_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m\n\u001b[1;32m     35\u001b[0m loader \u001b[38;5;241m=\u001b[39m DataLoader(\n\u001b[1;32m     36\u001b[0m             vol,\n\u001b[1;32m     37\u001b[0m             batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m     38\u001b[0m             num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m     39\u001b[0m             shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     40\u001b[0m         )\n",
      "File \u001b[0;32m~/Documents/EPFL/2024-25/MA1/CS-433 Machine learning/Project 2/nouveau-git/t3-dl-lob/Temporal_Fusion_Transform/data_formatters/ts_dataset.py:52\u001b[0m, in \u001b[0;36mTSDataset.__init__\u001b[0;34m(self, id_col, static_cols, time_col, input_cols, target_col, time_steps, max_samples, input_size, num_encoder_steps, num_static, output_size, data)\u001b[0m\n\u001b[1;32m     49\u001b[0m identifier, start_idx \u001b[38;5;241m=\u001b[39m tup\n\u001b[1;32m     50\u001b[0m sliced \u001b[38;5;241m=\u001b[39m split_data_map[identifier]\u001b[38;5;241m.\u001b[39miloc[start_idx \u001b[38;5;241m-\u001b[39m\n\u001b[1;32m     51\u001b[0m                                    \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime_steps:start_idx]\n\u001b[0;32m---> 52\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minputs[i, :, :] \u001b[38;5;241m=\u001b[39m \u001b[43msliced\u001b[49m\u001b[43m[\u001b[49m\u001b[43minput_cols\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutputs[i, :, :] \u001b[38;5;241m=\u001b[39m sliced[[target_col]]\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime[i, :, :] \u001b[38;5;241m=\u001b[39m sliced[time_col]\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/ML-project2/lib/python3.11/site-packages/pandas/core/frame.py:4117\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(indexer, \u001b[38;5;28mslice\u001b[39m):\n\u001b[1;32m   4115\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_slice(indexer, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m-> 4117\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_take_with_is_copy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4119\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_single_key:\n\u001b[1;32m   4120\u001b[0m     \u001b[38;5;66;03m# What does looking for a single key in a non-unique index return?\u001b[39;00m\n\u001b[1;32m   4121\u001b[0m     \u001b[38;5;66;03m# The behavior is inconsistent. It returns a Series, except when\u001b[39;00m\n\u001b[1;32m   4122\u001b[0m     \u001b[38;5;66;03m# - the key itself is repeated (test on data.shape, #9519), or\u001b[39;00m\n\u001b[1;32m   4123\u001b[0m     \u001b[38;5;66;03m# - we have a MultiIndex on columns (test on self.columns, #21309)\u001b[39;00m\n\u001b[1;32m   4124\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns, MultiIndex):\n\u001b[1;32m   4125\u001b[0m         \u001b[38;5;66;03m# GH#26490 using data[key] can cause RecursionError\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/ML-project2/lib/python3.11/site-packages/pandas/core/generic.py:4153\u001b[0m, in \u001b[0;36mNDFrame._take_with_is_copy\u001b[0;34m(self, indices, axis)\u001b[0m\n\u001b[1;32m   4142\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[1;32m   4143\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_take_with_is_copy\u001b[39m(\u001b[38;5;28mself\u001b[39m, indices, axis: Axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Self:\n\u001b[1;32m   4144\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4145\u001b[0m \u001b[38;5;124;03m    Internal version of the `take` method that sets the `_is_copy`\u001b[39;00m\n\u001b[1;32m   4146\u001b[0m \u001b[38;5;124;03m    attribute to keep track of the parent dataframe (using in indexing\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4151\u001b[0m \u001b[38;5;124;03m    See the docstring of `take` for full explanation of the parameters.\u001b[39;00m\n\u001b[1;32m   4152\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4153\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4154\u001b[0m     \u001b[38;5;66;03m# Maybe set copy if we didn't actually change the index.\u001b[39;00m\n\u001b[1;32m   4155\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m result\u001b[38;5;241m.\u001b[39m_get_axis(axis)\u001b[38;5;241m.\u001b[39mequals(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_axis(axis)):\n",
      "File \u001b[0;32m~/anaconda3/envs/ML-project2/lib/python3.11/site-packages/pandas/core/generic.py:4133\u001b[0m, in \u001b[0;36mNDFrame.take\u001b[0;34m(self, indices, axis, **kwargs)\u001b[0m\n\u001b[1;32m   4128\u001b[0m     \u001b[38;5;66;03m# We can get here with a slice via DataFrame.__getitem__\u001b[39;00m\n\u001b[1;32m   4129\u001b[0m     indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(\n\u001b[1;32m   4130\u001b[0m         indices\u001b[38;5;241m.\u001b[39mstart, indices\u001b[38;5;241m.\u001b[39mstop, indices\u001b[38;5;241m.\u001b[39mstep, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mintp\n\u001b[1;32m   4131\u001b[0m     )\n\u001b[0;32m-> 4133\u001b[0m new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4134\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4135\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_block_manager_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4136\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverify\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   4137\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4138\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(new_data, axes\u001b[38;5;241m=\u001b[39mnew_data\u001b[38;5;241m.\u001b[39maxes)\u001b[38;5;241m.\u001b[39m__finalize__(\n\u001b[1;32m   4139\u001b[0m     \u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtake\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4140\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/ML-project2/lib/python3.11/site-packages/pandas/core/internals/managers.py:894\u001b[0m, in \u001b[0;36mBaseBlockManager.take\u001b[0;34m(self, indexer, axis, verify)\u001b[0m\n\u001b[1;32m    891\u001b[0m indexer \u001b[38;5;241m=\u001b[39m maybe_convert_indices(indexer, n, verify\u001b[38;5;241m=\u001b[39mverify)\n\u001b[1;32m    893\u001b[0m new_labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes[axis]\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m--> 894\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreindex_indexer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    895\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnew_axis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_labels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    896\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindexer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    897\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    898\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_dups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    899\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    900\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/ML-project2/lib/python3.11/site-packages/pandas/core/internals/managers.py:680\u001b[0m, in \u001b[0;36mBaseBlockManager.reindex_indexer\u001b[0;34m(self, new_axis, indexer, axis, fill_value, allow_dups, copy, only_slice, use_na_proxy)\u001b[0m\n\u001b[1;32m    677\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRequested axis not found in manager\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    679\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 680\u001b[0m     new_blocks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_slice_take_blocks_ax0\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    682\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    683\u001b[0m \u001b[43m        \u001b[49m\u001b[43monly_slice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43monly_slice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    684\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_na_proxy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_na_proxy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    685\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    686\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    687\u001b[0m     new_blocks \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    688\u001b[0m         blk\u001b[38;5;241m.\u001b[39mtake_nd(\n\u001b[1;32m    689\u001b[0m             indexer,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    695\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m blk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks\n\u001b[1;32m    696\u001b[0m     ]\n",
      "File \u001b[0;32m~/anaconda3/envs/ML-project2/lib/python3.11/site-packages/pandas/core/internals/managers.py:843\u001b[0m, in \u001b[0;36mBaseBlockManager._slice_take_blocks_ax0\u001b[0;34m(self, slice_or_indexer, fill_value, only_slice, use_na_proxy, ref_inplace_op)\u001b[0m\n\u001b[1;32m    841\u001b[0m                     blocks\u001b[38;5;241m.\u001b[39mappend(nb)\n\u001b[1;32m    842\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 843\u001b[0m                 nb \u001b[38;5;241m=\u001b[39m \u001b[43mblk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake_nd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtaker\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_mgr_locs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmgr_locs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    844\u001b[0m                 blocks\u001b[38;5;241m.\u001b[39mappend(nb)\n\u001b[1;32m    846\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m blocks\n",
      "File \u001b[0;32m~/anaconda3/envs/ML-project2/lib/python3.11/site-packages/pandas/core/internals/blocks.py:1325\u001b[0m, in \u001b[0;36mBlock.take_nd\u001b[0;34m(self, indexer, axis, new_mgr_locs, fill_value)\u001b[0m\n\u001b[1;32m   1323\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_block(new_values, new_mgr_locs)\n\u001b[1;32m   1324\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1325\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_block_same_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_mgr_locs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/ML-project2/lib/python3.11/site-packages/pandas/core/internals/blocks.py:292\u001b[0m, in \u001b[0;36mBlock.make_block_same_class\u001b[0;34m(self, values, placement, refs)\u001b[0m\n\u001b[1;32m    288\u001b[0m         values \u001b[38;5;241m=\u001b[39m ensure_block_shape(values, ndim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim)\n\u001b[1;32m    290\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m new_block(values, placement\u001b[38;5;241m=\u001b[39mplacement, ndim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim, refs\u001b[38;5;241m=\u001b[39mrefs)\n\u001b[0;32m--> 292\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[1;32m    293\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmake_block_same_class\u001b[39m(\n\u001b[1;32m    294\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    295\u001b[0m     values,\n\u001b[1;32m    296\u001b[0m     placement: BlockPlacement \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    297\u001b[0m     refs: BlockValuesRefs \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    298\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Self:\n\u001b[1;32m    299\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Wrap given values in a block of same type as self.\"\"\"\u001b[39;00m\n\u001b[1;32m    300\u001b[0m     \u001b[38;5;66;03m# Pre-2.0 we called ensure_wrapped_if_datetimelike because fastparquet\u001b[39;00m\n\u001b[1;32m    301\u001b[0m     \u001b[38;5;66;03m#  relied on it, as of 2.0 the caller is responsible for this.\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Run the model for different horizons\n",
    "for horizon in [20, 50, 100] :\n",
    "    model, loader = initialize_Transformer(horizon)\n",
    "    print(f'Training for horizon {horizon}')\n",
    "    run_model(model, loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML-project2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
